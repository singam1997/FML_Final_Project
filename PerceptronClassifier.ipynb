{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PerceptronClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO6JDf9eIoSS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.mode.chained_assignment=None\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUh5LZWJZbT6"
      },
      "source": [
        "df=pd.read_csv(\"diabetes_training.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lyeh-wkJYBb"
      },
      "source": [
        "#Preprocessing\n",
        "#Changing 0 values in Glucose, BloodPressure and BMI\n",
        "df_nodiab=df[df[\"Outcome\"]==0]\n",
        "df_diab=df[df[\"Outcome\"]==1]\n",
        "glucose_count_0=0\n",
        "glucose_count_1=0\n",
        "bloodpressure_count_0=0\n",
        "bloodpressure_count_1=0\n",
        "bmi_count_0=0\n",
        "bmi_count_1=0\n",
        "glucose=df_nodiab[\"Glucose\"]\n",
        "bloodpressure=df_nodiab[\"BloodPressure\"]\n",
        "bmi=df_nodiab[\"BMI\"]\n",
        "for i in glucose:\n",
        "  if i==0:\n",
        "    glucose_count_0=glucose_count_0+1\n",
        "for i in bloodpressure:\n",
        "  if i==0:\n",
        "    bloodpressure_count_0=bloodpressure_count_0+1\n",
        "for i in bmi:\n",
        "  if i==0:\n",
        "    bmi_count_0=bmi_count_0+1\n",
        "avg_glucose_0=np.mean(glucose)*(glucose.shape[0]/(glucose.shape[0]-glucose_count_0))\n",
        "avg_bloodpressure_0=np.mean(bloodpressure)*(bloodpressure.shape[0]/(bloodpressure.shape[0]-bloodpressure_count_0))\n",
        "avg_bmi_0=np.mean(bmi)*(bmi.shape[0]/(bmi.shape[0]-bmi_count_0))\n",
        "glucose=df_diab[\"Glucose\"]\n",
        "bloodpressure=df_diab[\"BloodPressure\"]\n",
        "bmi=df_diab[\"BMI\"]\n",
        "for i in glucose:\n",
        "  if i==0:\n",
        "    glucose_count_1=glucose_count_1+1\n",
        "for i in bloodpressure:\n",
        "  if i==0:\n",
        "    bloodpressure_count_1=bloodpressure_count_1+1\n",
        "for i in bmi:\n",
        "  if i==0:\n",
        "    bmi_count_1=bmi_count_1+1\n",
        "avg_glucose_1=np.mean(glucose)*(glucose.shape[0]/(glucose.shape[0]-glucose_count_1))\n",
        "avg_bloodpressure_1=np.mean(bloodpressure)*(bloodpressure.shape[0]/(bloodpressure.shape[0]-bloodpressure_count_1))\n",
        "avg_bmi_1=np.mean(bmi)*(bmi.shape[0]/(bmi.shape[0]-bmi_count_1))\n",
        "arr=df.values\n",
        "for i in arr:\n",
        "  if i[8]==0:\n",
        "    if i[1]==0:\n",
        "      i[1]=avg_glucose_0\n",
        "    if i[2]==0:\n",
        "      i[2]=avg_bloodpressure_0\n",
        "    if i[5]==0:\n",
        "      i[5]=avg_bmi_0\n",
        "  else:\n",
        "    if i[1]==0:\n",
        "      i[1]=avg_glucose_1\n",
        "    if i[2]==0:\n",
        "      i[2]=avg_bloodpressure_1\n",
        "    if i[5]==0:\n",
        "      i[5]=avg_bmi_1\n",
        "df=pd.DataFrame(arr,index=df.index,columns=df.columns)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOB7oPFQK-Rt"
      },
      "source": [
        "x_columns=[\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]\n",
        "df_x=df[x_columns]\n",
        "scaler=StandardScaler()\n",
        "scaled=scaler.fit_transform(df_x)\n",
        "df_x=pd.DataFrame(scaled,index=df_x.index,columns=df_x.columns)\n",
        "df[x_columns]=df_x\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKkj_HYjP2Ex"
      },
      "source": [
        "X=df[x_columns].values\n",
        "Y=df[\"Outcome\"].values\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkBLEwo5XUaj"
      },
      "source": [
        "model=Perceptron(class_weight=\"balanced\")\n",
        "model.fit(X_train,Y_train)\n",
        "Y_hat=model.predict(X_test)\n",
        "print(\"Accuracy: \",accuracy_score(Y_test,Y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIJmzF-vX9fs"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(Y_test, Y_hat)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(Y_test, Y_hat)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(Y_test, Y_hat)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(Y_test, Y_hat)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RoG3t4C9ffQ"
      },
      "source": [
        "confusion_matrix(Y_test, Y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCA1L7vBlg30"
      },
      "source": [
        "df_train=pd.read_csv(\"diabetes_training.csv\")\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7q3FoCflr0e"
      },
      "source": [
        "X_train=df_train[x_columns].values\n",
        "Y_train=df_train[\"Outcome\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8hqnVUUl8U4"
      },
      "source": [
        "model=Perceptron()\n",
        "model.fit(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzW-lZDrmUBz"
      },
      "source": [
        "df_test=pd.read_csv(\"diabetes_testing.csv\")\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ojwe06dnFzM"
      },
      "source": [
        "X_test=df_test[x_columns].values\n",
        "Y_test=df_test[\"Outcome\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GRFanJGnKbD"
      },
      "source": [
        "Y_hat=model.predict(X_test)\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(Y_test, Y_hat)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(Y_test, Y_hat)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(Y_test, Y_hat)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(Y_test, Y_hat)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saGIenfSs_e-"
      },
      "source": [
        "Y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vxduz1kaCsG"
      },
      "source": [
        "## Hyper-parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eWYol_caEkG"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'l1_ratio': [0.1,0.15,0.3,0.5,0.7,0.9],\n",
        "\n",
        "              'alpha':[1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001,\n",
        "                                   1e-05, 1e-06, 1e-07, 1e-07, 1e-08, 1e-09,\n",
        "                                   1e-10, 1e-11],\n",
        "              'tol':[1e-3,1e-2,1e-6],\n",
        "              'max_iter':[1000,10000,100000,10000000],\n",
        "                'early_stopping':[True,False],\n",
        "              'penalty': [None,'l2','l1','elasticnet']}\n",
        "\n",
        "grid = GridSearchCV(Perceptron(class_weight=\"balanced\"), param_grid, refit = True, verbose = 3,n_jobs=10)\n",
        "\n",
        "# grid.fit(X_train, Y_train)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(grid, X_train, Y_train, cv=5)\n",
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ykbCh5a_F5"
      },
      "source": [
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVoanSdtbB77"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(Y_train, grid.predict(X_train))\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(Y_train,  grid.predict(X_train)))\n",
        "\n",
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, annot=True, fmt='g')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7kje_ek8I9-"
      },
      "source": [
        "# RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_ho_P9t9mgj"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler # Up-sample or Down-sample\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_res, Y_res = rus.fit_resample(X, Y)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.005)\n",
        "\n",
        "print(\"Training data set shape : \", X_train.shape, Y_train.shape)\n",
        "print(\"Test data set shape : \", X_test.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R21BSII67d6S"
      },
      "source": [
        "model=Perceptron()\n",
        "model.fit(X_train,Y_train)\n",
        "Y_hat=model.predict(X_test)\n",
        "print(\"Accuracy: \",accuracy_score(Y_test,Y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcaQ6qsy8SZD"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(Y_test, Y_hat)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(Y_test, Y_hat)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(Y_test, Y_hat)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(Y_test, Y_hat)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20_d7BkA8V9w"
      },
      "source": [
        "confusion_matrix(Y_test, Y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9NK0xMM8YJs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}